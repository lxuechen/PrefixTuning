#!/bin/bash
mkdir -p /nlp/scr/lxuechen/prefixtune/date_081221/fulltune/distilgpt2-24-768 
CUDA_VISIBLE_DEVICES=3 python -m gpt2stuff.launchers.prefix_vs_full_062021 --mode "local" --tuning_mode fulltune --max_seq_len 100 --nonprivate "no" --per_device_train_batch_size 32 --gradient_accumulation_steps 16 --learning_rate 0.0005 --per_example_max_grad_norm 0.1 --target_epsilon 8 --epochs 50 --eval_epochs 5 --private_engine_mode "ghost"   --model_name_or_path "/home/lxuechen_stanford_edu/dump/distilgpt2/date_080210/distilgpt2-24-768" --max_generations_train 20 --train_dir /nlp/scr/lxuechen/prefixtune/date_081221/fulltune/distilgpt2-24-768 |& tee /nlp/scr/lxuechen/prefixtune/date_081221/fulltune/distilgpt2-24-768/log.out & 
mkdir -p /nlp/scr/lxuechen/prefixtune/date_081221/fulltune/distilgpt2-26-832 
CUDA_VISIBLE_DEVICES=4 python -m gpt2stuff.launchers.prefix_vs_full_062021 --mode "local" --tuning_mode fulltune --max_seq_len 100 --nonprivate "no" --per_device_train_batch_size 32 --gradient_accumulation_steps 16 --learning_rate 0.0005 --per_example_max_grad_norm 0.1 --target_epsilon 8 --epochs 50 --eval_epochs 5 --private_engine_mode "ghost"   --model_name_or_path "/home/lxuechen_stanford_edu/dump/distilgpt2/date_080210/distilgpt2-26-832" --max_generations_train 20 --train_dir /nlp/scr/lxuechen/prefixtune/date_081221/fulltune/distilgpt2-26-832 |& tee /nlp/scr/lxuechen/prefixtune/date_081221/fulltune/distilgpt2-26-832/log.out & 
mkdir -p /nlp/scr/lxuechen/prefixtune/date_081221/fulltune/distilgpt2-28-896 
CUDA_VISIBLE_DEVICES=5 python -m gpt2stuff.launchers.prefix_vs_full_062021 --mode "local" --tuning_mode fulltune --max_seq_len 100 --nonprivate "no" --per_device_train_batch_size 32 --gradient_accumulation_steps 16 --learning_rate 0.0005 --per_example_max_grad_norm 0.1 --target_epsilon 8 --epochs 50 --eval_epochs 5 --private_engine_mode "ghost"   --model_name_or_path "/home/lxuechen_stanford_edu/dump/distilgpt2/date_080210/distilgpt2-28-896" --max_generations_train 20 --train_dir /nlp/scr/lxuechen/prefixtune/date_081221/fulltune/distilgpt2-28-896 |& tee /nlp/scr/lxuechen/prefixtune/date_081221/fulltune/distilgpt2-28-896/log.out & 
mkdir -p /nlp/scr/lxuechen/prefixtune/date_081221/fulltune/distilgpt2-30-960 
CUDA_VISIBLE_DEVICES=6 python -m gpt2stuff.launchers.prefix_vs_full_062021 --mode "local" --tuning_mode fulltune --max_seq_len 100 --nonprivate "no" --per_device_train_batch_size 32 --gradient_accumulation_steps 16 --learning_rate 0.0005 --per_example_max_grad_norm 0.1 --target_epsilon 8 --epochs 50 --eval_epochs 5 --private_engine_mode "ghost"   --model_name_or_path "/home/lxuechen_stanford_edu/dump/distilgpt2/date_080210/distilgpt2-30-960" --max_generations_train 20 --train_dir /nlp/scr/lxuechen/prefixtune/date_081221/fulltune/distilgpt2-30-960 |& tee /nlp/scr/lxuechen/prefixtune/date_081221/fulltune/distilgpt2-30-960/log.out & 
wait
mkdir -p /nlp/scr/lxuechen/prefixtune/date_081221/scratchtune/distilgpt2-24-768 
CUDA_VISIBLE_DEVICES=3 python -m gpt2stuff.launchers.prefix_vs_full_062021 --mode "local" --tuning_mode scratchtune --max_seq_len 100 --nonprivate "no" --per_device_train_batch_size 32 --gradient_accumulation_steps 16 --learning_rate 0.0005 --per_example_max_grad_norm 0.1 --target_epsilon 8 --epochs 50 --eval_epochs 5 --private_engine_mode "ghost"   --model_name_or_path "/home/lxuechen_stanford_edu/dump/distilgpt2/date_080210/distilgpt2-24-768" --max_generations_train 20 --train_dir /nlp/scr/lxuechen/prefixtune/date_081221/scratchtune/distilgpt2-24-768 |& tee /nlp/scr/lxuechen/prefixtune/date_081221/scratchtune/distilgpt2-24-768/log.out & 
mkdir -p /nlp/scr/lxuechen/prefixtune/date_081221/scratchtune/distilgpt2-26-832 
CUDA_VISIBLE_DEVICES=4 python -m gpt2stuff.launchers.prefix_vs_full_062021 --mode "local" --tuning_mode scratchtune --max_seq_len 100 --nonprivate "no" --per_device_train_batch_size 32 --gradient_accumulation_steps 16 --learning_rate 0.0005 --per_example_max_grad_norm 0.1 --target_epsilon 8 --epochs 50 --eval_epochs 5 --private_engine_mode "ghost"   --model_name_or_path "/home/lxuechen_stanford_edu/dump/distilgpt2/date_080210/distilgpt2-26-832" --max_generations_train 20 --train_dir /nlp/scr/lxuechen/prefixtune/date_081221/scratchtune/distilgpt2-26-832 |& tee /nlp/scr/lxuechen/prefixtune/date_081221/scratchtune/distilgpt2-26-832/log.out & 
mkdir -p /nlp/scr/lxuechen/prefixtune/date_081221/scratchtune/distilgpt2-28-896 
CUDA_VISIBLE_DEVICES=5 python -m gpt2stuff.launchers.prefix_vs_full_062021 --mode "local" --tuning_mode scratchtune --max_seq_len 100 --nonprivate "no" --per_device_train_batch_size 32 --gradient_accumulation_steps 16 --learning_rate 0.0005 --per_example_max_grad_norm 0.1 --target_epsilon 8 --epochs 50 --eval_epochs 5 --private_engine_mode "ghost"   --model_name_or_path "/home/lxuechen_stanford_edu/dump/distilgpt2/date_080210/distilgpt2-28-896" --max_generations_train 20 --train_dir /nlp/scr/lxuechen/prefixtune/date_081221/scratchtune/distilgpt2-28-896 |& tee /nlp/scr/lxuechen/prefixtune/date_081221/scratchtune/distilgpt2-28-896/log.out & 
mkdir -p /nlp/scr/lxuechen/prefixtune/date_081221/scratchtune/distilgpt2-30-960 
CUDA_VISIBLE_DEVICES=6 python -m gpt2stuff.launchers.prefix_vs_full_062021 --mode "local" --tuning_mode scratchtune --max_seq_len 100 --nonprivate "no" --per_device_train_batch_size 32 --gradient_accumulation_steps 16 --learning_rate 0.0005 --per_example_max_grad_norm 0.1 --target_epsilon 8 --epochs 50 --eval_epochs 5 --private_engine_mode "ghost"   --model_name_or_path "/home/lxuechen_stanford_edu/dump/distilgpt2/date_080210/distilgpt2-30-960" --max_generations_train 20 --train_dir /nlp/scr/lxuechen/prefixtune/date_081221/scratchtune/distilgpt2-30-960 |& tee /nlp/scr/lxuechen/prefixtune/date_081221/scratchtune/distilgpt2-30-960/log.out & 
wait
